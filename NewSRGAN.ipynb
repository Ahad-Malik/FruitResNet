{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WfpUOpTh6JCX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qRKjZPaN6ee8"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mbHM6U9_7HXF"
      },
      "outputs": [],
      "source": [
        "# Define RRDBNet architecture\n",
        "def make_layer(block, n_layers):\n",
        "    layers = []\n",
        "    for _ in range(n_layers):\n",
        "        layers.append(block())\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResidualDenseBlock_5C(nn.Module):\n",
        "    def __init__(self, nf=64, gc=32, bias=True):\n",
        "        super(ResidualDenseBlock_5C, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(nf, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv2 = nn.Conv2d(nf + gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv3 = nn.Conv2d(nf + 2 * gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv4 = nn.Conv2d(nf + 3 * gc, gc, 3, 1, 1, bias=bias)\n",
        "        self.conv5 = nn.Conv2d(nf + 4 * gc, nf, 3, 1, 1, bias=bias)\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.lrelu(self.conv1(x))\n",
        "        x2 = self.lrelu(self.conv2(torch.cat((x, x1), 1)))\n",
        "        x3 = self.lrelu(self.conv3(torch.cat((x, x1, x2), 1)))\n",
        "        x4 = self.lrelu(self.conv4(torch.cat((x, x1, x2, x3), 1)))\n",
        "        x5 = self.conv5(torch.cat((x, x1, x2, x3, x4), 1))\n",
        "        return x5 * 0.2 + x\n",
        "\n",
        "class RRDB(nn.Module):\n",
        "    def __init__(self, nf, gc=32):\n",
        "        super(RRDB, self).__init__()\n",
        "        self.RDB1 = ResidualDenseBlock_5C(nf, gc)\n",
        "        self.RDB2 = ResidualDenseBlock_5C(nf, gc)\n",
        "        self.RDB3 = ResidualDenseBlock_5C(nf, gc)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.RDB1(x)\n",
        "        out = self.RDB2(out)\n",
        "        out = self.RDB3(out)\n",
        "        return out * 0.2 + x\n",
        "\n",
        "class RRDBNet(nn.Module):\n",
        "    def __init__(self, in_nc, out_nc, nf, nb, gc=32):\n",
        "        super(RRDBNet, self).__init__()\n",
        "        RRDB_block_f = lambda: RRDB(nf, gc)\n",
        "\n",
        "        self.conv_first = nn.Conv2d(in_nc, nf, 3, 1, 1, bias=True)\n",
        "        self.RRDB_trunk = make_layer(RRDB_block_f, nb)\n",
        "        self.trunk_conv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.upconv1 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.upconv2 = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.HRconv = nn.Conv2d(nf, nf, 3, 1, 1, bias=True)\n",
        "        self.conv_last = nn.Conv2d(nf, out_nc, 3, 1, 1, bias=True)\n",
        "        self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        fea = self.conv_first(x)\n",
        "        trunk = self.trunk_conv(self.RRDB_trunk(fea))\n",
        "        fea = fea + trunk\n",
        "        fea = self.lrelu(self.upconv1(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "        fea = self.lrelu(self.upconv2(F.interpolate(fea, scale_factor=2, mode='nearest')))\n",
        "        out = self.conv_last(self.lrelu(self.HRconv(fea)))\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "46feCv105o2T"
      },
      "outputs": [],
      "source": [
        "class PomegranateDataset(Dataset):\n",
        "    def __init__(self, hr_dir, lr_dir, transform=None):\n",
        "        self.hr_dir = hr_dir\n",
        "        self.lr_dir = lr_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = os.listdir(hr_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        hr_path = os.path.join(self.hr_dir, self.image_files[idx])\n",
        "        lr_path = os.path.join(self.lr_dir, self.image_files[idx])\n",
        "\n",
        "        hr_image = Image.open(hr_path).convert('RGB')\n",
        "        lr_image = Image.open(lr_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            hr_image = self.transform(hr_image)\n",
        "            lr_image = self.transform(lr_image)\n",
        "\n",
        "        return lr_image, hr_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mysJRSgK5qv7"
      },
      "outputs": [],
      "source": [
        "# Set up data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ootaby1R5s_s"
      },
      "outputs": [],
      "source": [
        "# Create dataset and dataloader\n",
        "train_dataset = PomegranateDataset('HR', 'LR', transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6h8XpIU5vbO"
      },
      "outputs": [],
      "source": [
        "# Initialize the model with pretrained weights\n",
        "model = RRDBNet(3, 3, 64, 23, gc=32).to(device)\n",
        "pretrained_weights = torch.load('models/RRDB_ESRGAN_x4.pth')\n",
        "model.load_state_dict(pretrained_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GNte0UGb5x2b"
      },
      "outputs": [],
      "source": [
        "# Freeze early layers (optional)\n",
        "for name, param in model.named_parameters():\n",
        "    if 'conv_first' in name or 'RRDB_trunk.0' in name or 'RRDB_trunk.1' in name:\n",
        "        param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jnQ-exzV50GT"
      },
      "outputs": [],
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.L1Loss()\n",
        "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.0001, betas=(0.9, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bMcr7J_652NQ"
      },
      "outputs": [],
      "source": [
        "# Learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def __getitem__(self, idx):\n",
        "    try:\n",
        "        hr_path = os.path.join(self.hr_dir, self.image_files[idx])\n",
        "        lr_path = os.path.join(self.lr_dir, self.image_files[idx])\n",
        "\n",
        "        hr_image = Image.open(hr_path).convert('RGB')\n",
        "        lr_image = Image.open(lr_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            hr_image = self.transform(hr_image)\n",
        "            lr_image = self.transform(lr_image)\n",
        "\n",
        "        return lr_image, hr_image\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image {self.image_files[idx]}: {str(e)}\")\n",
        "        # Return a placeholder or skip this image\n",
        "        return torch.zeros(3, 224, 224), torch.zeros(3, 224, 224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training loop\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for batch_idx, (lr_imgs, hr_imgs) in enumerate(train_loader):\n",
        "        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        sr_imgs = model(lr_imgs)\n",
        "        loss = criterion(sr_imgs, hr_imgs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "        if (batch_idx + 1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Step the scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Validation step (implement as needed)\n",
        "\n",
        "    # Save checkpoint\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': avg_loss,\n",
        "        }, f'pomegranate_srgan_epoch_{epoch+1}.pth')\n",
        "\n",
        "print(\"Fine-tuning completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ciOFq8aR5_DI"
      },
      "outputs": [],
      "source": [
        "# Function to test the model on a single image\n",
        "def test_single_image(model, image_path):\n",
        "    model.eval()\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    img = Image.open(image_path).convert('RGB')\n",
        "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(img_tensor)\n",
        "\n",
        "    # Denormalize and convert to PIL Image\n",
        "    output = output.squeeze().cpu().clamp(0, 1).permute(1, 2, 0).numpy()\n",
        "    output = (output * 255).astype('uint8')\n",
        "    output_img = Image.fromarray(output)\n",
        "\n",
        "    return output_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKoZBndW6Buy"
      },
      "outputs": [],
      "source": [
        "# Test the model on a sample image\n",
        "test_img_path = 'path/to/test/pomegranate/image.jpg'\n",
        "result_img = test_single_image(model, test_img_path)\n",
        "result_img.save('enhanced_pomegranate.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SyXZLiY-sCd",
        "outputId": "4d196335-c2c2-4019-aeb5-6968c892ef87"
      },
      "outputs": [],
      "source": [
        "# Function to create interpolated model\n",
        "def interpolate_model(alpha):\n",
        "    try:\n",
        "        net_PSNR = torch.load('models/RRDB_PSNR_x4 (1).pth', map_location=device)\n",
        "        net_ESRGAN = torch.load('models/RRDB_ESRGAN_x4.pth', map_location=device)\n",
        "        net_interp = OrderedDict()\n",
        "\n",
        "        for k, v_PSNR in net_PSNR.items():\n",
        "            v_ESRGAN = net_ESRGAN[k]\n",
        "            net_interp[k] = (1 - alpha) * v_PSNR + alpha * v_ESRGAN\n",
        "\n",
        "        return net_interp\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating interpolated model: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Create interpolated models\n",
        "print(\"Creating interpolated models...\")\n",
        "interp_05 = interpolate_model(0.5)\n",
        "interp_08 = interpolate_model(0.8)\n",
        "\n",
        "# Save interpolated models\n",
        "if interp_05 is not None and interp_08 is not None:\n",
        "    torch.save(interp_05, 'models/interp_05.pth')\n",
        "    torch.save(interp_08, 'models/interp_08.pth')\n",
        "    print(\"Interpolated models created and saved.\")\n",
        "else:\n",
        "    print(\"Failed to create interpolated models.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rz_a-C7d6hX7"
      },
      "outputs": [],
      "source": [
        "# Define model paths\n",
        "model_paths = {\n",
        "    'PSNR': 'models/RRDB_PSNR_x4 (1).pth',\n",
        "    'ESRGAN': 'models/RRDB_ESRGAN_x4.pth',\n",
        "    'Interp_0.5': 'models/interp_05.pth',\n",
        "    'Interp_0.8': 'models/interp_08.pth'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7Nc-N-l7OJv"
      },
      "outputs": [],
      "source": [
        "# Function to load model\n",
        "def load_model(model_path):\n",
        "    model = RRDBNet(3, 3, 64, 23, gc=32)\n",
        "    model.load_state_dict(torch.load(model_path), strict=True)\n",
        "    model.eval()\n",
        "    return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrAINhjd7Pxj"
      },
      "outputs": [],
      "source": [
        "# Function to process image\n",
        "def process_image(model, img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "    img = img * 1.0 / 255\n",
        "    img = torch.from_numpy(np.transpose(img[:, :, [2, 1, 0]], (2, 0, 1))).float()\n",
        "    img_LR = img.unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(img_LR).data.squeeze().float().cpu().clamp_(0, 1).numpy()\n",
        "\n",
        "    output = np.transpose(output[[2, 1, 0], :, :], (1, 2, 0))\n",
        "    return (output * 255.0).round().astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXsCyhcz7RcJ"
      },
      "outputs": [],
      "source": [
        "# Function to calculate PSNR\n",
        "def calculate_psnr(img1, img2):\n",
        "    mse = np.mean((img1 - img2) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    return 20 * np.log10(255.0 / np.sqrt(mse))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "554cQr4V7TGN"
      },
      "outputs": [],
      "source": [
        "# Function to calculate SSIM\n",
        "def calculate_ssim(img1, img2):\n",
        "    C1 = (0.01 * 255)**2\n",
        "    C2 = (0.03 * 255)**2\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    kernel = cv2.getGaussianKernel(11, 1.5)\n",
        "    window = np.outer(kernel, kernel.transpose())\n",
        "    mu1 = cv2.filter2D(img1, -1, window)[5:-5, 5:-5]\n",
        "    mu2 = cv2.filter2D(img2, -1, window)[5:-5, 5:-5]\n",
        "    mu1_sq = mu1**2\n",
        "    mu2_sq = mu2**2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = cv2.filter2D(img1**2, -1, window)[5:-5, 5:-5] - mu1_sq\n",
        "    sigma2_sq = cv2.filter2D(img2**2, -1, window)[5:-5, 5:-5] - mu2_sq\n",
        "    sigma12 = cv2.filter2D(img1 * img2, -1, window)[5:-5, 5:-5] - mu1_mu2\n",
        "    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "    return ssim_map.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFevPiZD9Xyp"
      },
      "outputs": [],
      "source": [
        "# Modified function to load model\n",
        "def load_model(model_path):\n",
        "    model = RRDBNet(3, 3, 64, 23, gc=32)\n",
        "    try:\n",
        "        state_dict = torch.load(model_path, map_location=device)\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "        print(f\"Successfully loaded model from {model_path}\")\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error loading model from {model_path}: {str(e)}\")\n",
        "        print(\"Attempting to load with strict=False...\")\n",
        "        try:\n",
        "            model.load_state_dict(state_dict, strict=False)\n",
        "            print(f\"Loaded model from {model_path} with strict=False\")\n",
        "        except Exception as e:\n",
        "            print(f\"Failed to load model from {model_path}: {str(e)}\")\n",
        "            return None\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Model file not found: {model_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error loading model from {model_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    model.eval()\n",
        "    return model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0HI5XCd7Ujt",
        "outputId": "3ce26cfd-2667-4deb-864c-3ab04db36494"
      },
      "outputs": [],
      "source": [
        "# Load all models\n",
        "models = {}\n",
        "for name, path in model_paths.items():\n",
        "    print(f\"Attempting to load {name} model...\")\n",
        "    model = load_model(path)\n",
        "    if model is not None:\n",
        "        models[name] = model\n",
        "    else:\n",
        "        print(f\"Skipping {name} model due to loading failure\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cghi1X5xBgKJ"
      },
      "outputs": [],
      "source": [
        "def process_image(model, img_path):\n",
        "    # Read image in BGR format (OpenCV default)\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert BGR to RGB\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Normalize to [0, 1]\n",
        "    img = img.astype(np.float32) / 255.\n",
        "\n",
        "    # Convert to tensor and add batch dimension\n",
        "    img = torch.from_numpy(np.transpose(img, (2, 0, 1))).float().unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(img).squeeze().float().cpu().clamp_(0, 1).numpy()\n",
        "\n",
        "    # Convert back to uint8 and BGR for saving\n",
        "    output = (np.transpose(output, (1, 2, 0)) * 255.0).round().astype(np.uint8)\n",
        "    output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTZpMuI9BljH"
      },
      "outputs": [],
      "source": [
        "def process_and_display(img_path):\n",
        "    # Read original image\n",
        "    original = cv2.imread(img_path)\n",
        "    original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process image with each model\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        print(f\"Processing with {name} model...\")\n",
        "        result = process_image(model, img_path)\n",
        "        if result is not None:\n",
        "            results[name] = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)  # Convert back to RGB for display\n",
        "        else:\n",
        "            print(f\"Skipping {name} model due to processing failure\")\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {}\n",
        "    for name, result in results.items():\n",
        "        print(f\"Calculating metrics for {name} model...\")\n",
        "        # Resize original image to match the dimensions of the processed image\n",
        "        resized_original = cv2.resize(original, (result.shape[1], result.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
        "        metrics[name] = {\n",
        "            'PSNR': calculate_psnr(resized_original, result),\n",
        "            'SSIM': calculate_ssim(resized_original, result)\n",
        "        }\n",
        "\n",
        "    # Display results\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(20, 15))\n",
        "    fig.suptitle(f'Super-Resolution Results for {os.path.basename(img_path)}', fontsize=16)\n",
        "\n",
        "    axes[0, 0].imshow(original)\n",
        "    axes[0, 0].set_title('Original')\n",
        "    axes[0, 0].axis('off')\n",
        "\n",
        "    for idx, (name, result) in enumerate(results.items(), 1):\n",
        "        row, col = divmod(idx, 3)\n",
        "        axes[row, col].imshow(result)\n",
        "        axes[row, col].set_title(f'{name}\\nPSNR: {metrics[name][\"PSNR\"]:.2f}, SSIM: {metrics[name][\"SSIM\"]:.4f}')\n",
        "        axes[row, col].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dllGgf-qBm8X",
        "outputId": "b383dbbf-49ca-49dd-889c-52069de33167"
      },
      "outputs": [],
      "source": [
        "# Process images\n",
        "test_img_folder = 'LR/*'\n",
        "for img_path in glob.glob(test_img_folder)[:3]:  # Process first 3 images\n",
        "    print(f\"\\nProcessing {img_path}\")\n",
        "    try:\n",
        "        metrics = process_and_display(img_path)\n",
        "\n",
        "        # Print metrics in a table format\n",
        "        print(\"\\nMetrics:\")\n",
        "        print(f\"{'Model':<15} {'PSNR':>10} {'SSIM':>10}\")\n",
        "        print(\"-\" * 35)\n",
        "        for model, values in metrics.items():\n",
        "            print(f\"{model:<15} {values['PSNR']:10.2f} {values['SSIM']:10.4f}\")\n",
        "        print(\"\\n\")\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nProcessing interrupted by user. Moving to the next image.\")\n",
        "        continue\n",
        "    except Exception as e:\n",
        "        print(f\"\\nUnexpected error processing {img_path}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "print(\"Image processing completed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lM-J4Uf87gY1"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "def calculate_ssim(img1, img2):\n",
        "    # Ensure the images have the same shape\n",
        "    if img1.shape != img2.shape:\n",
        "        img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))\n",
        "\n",
        "    # Convert images to float32 if they're not already\n",
        "    img1 = img1.astype(np.float32)\n",
        "    img2 = img2.astype(np.float32)\n",
        "\n",
        "    # Normalize images to [0, 1] range if they're not already\n",
        "    if img1.max() > 1.0:\n",
        "        img1 /= 255.0\n",
        "    if img2.max() > 1.0:\n",
        "        img2 /= 255.0\n",
        "\n",
        "    # Ensure the images have 3 channels (RGB)\n",
        "    if len(img1.shape) == 2:\n",
        "        img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2RGB)\n",
        "    if len(img2.shape) == 2:\n",
        "        img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    # Calculate SSIM\n",
        "    min_dim = min(img1.shape[0], img1.shape[1])\n",
        "    win_size = min(7, min_dim)  # Use 7 or smaller odd number\n",
        "\n",
        "    # Ensure win_size is odd\n",
        "    if win_size % 2 == 0:\n",
        "        win_size -= 1\n",
        "\n",
        "    return ssim(img1, img2, win_size=win_size, channel_axis=2, data_range=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwIUZ1WPQVv2",
        "outputId": "028c44db-4c76-4539-d5cb-edc51d012c86"
      },
      "outputs": [],
      "source": [
        "# Aggregate results\n",
        "aggregate_metrics = {model: {'PSNR': [], 'SSIM': []} for model in models.keys()}\n",
        "\n",
        "for img_path in glob.glob(test_img_folder):\n",
        "    try:\n",
        "        original = cv2.imread(img_path)\n",
        "        if original is None:\n",
        "            print(f\"Error: Unable to read image {img_path}\")\n",
        "            continue\n",
        "        original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        print(f\"Processing {img_path} (shape: {original.shape})\")\n",
        "\n",
        "        for name, model in models.items():\n",
        "            result = process_image(model, img_path)\n",
        "            if result is None:\n",
        "                print(f\"Error: Unable to process image {img_path} with model {name}\")\n",
        "                continue\n",
        "            # Convert result back to RGB for metric calculation\n",
        "            result_rgb = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # Normalize images to [0, 1] range for PSNR calculation\n",
        "            original_norm = original.astype(np.float32) / 255.0\n",
        "            result_norm = result_rgb.astype(np.float32) / 255.0\n",
        "\n",
        "            psnr = calculate_psnr(original_norm, result_norm)\n",
        "            ssim_value = calculate_ssim(original_norm, result_norm)\n",
        "\n",
        "            aggregate_metrics[name]['PSNR'].append(psnr)\n",
        "            aggregate_metrics[name]['SSIM'].append(ssim_value)\n",
        "\n",
        "            print(f\"  {name} model - PSNR: {psnr:.2f}, SSIM: {ssim_value:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {img_path}: {str(e)}\")\n",
        "        continue\n",
        "\n",
        "# Calculate average metrics\n",
        "avg_metrics = {model: {metric: np.mean(values) if values else np.nan for metric, values in metrics.items()}\n",
        "               for model, metrics in aggregate_metrics.items()}\n",
        "\n",
        "# Print aggregate results\n",
        "print(\"\\nAggregate Results:\")\n",
        "print(f\"{'Model':<15} {'Avg PSNR':>10} {'Avg SSIM':>10}\")\n",
        "print(\"-\" * 35)\n",
        "for model, values in avg_metrics.items():\n",
        "    print(f\"{model:<15} {values['PSNR']:10.2f} {values['SSIM']:10.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPo_duhs7jFm"
      },
      "outputs": [],
      "source": [
        "# Calculate average metrics\n",
        "avg_metrics = {model: {metric: np.mean(values) for metric, values in metrics.items()}\n",
        "               for model, metrics in aggregate_metrics.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUE1AAQA7lR7",
        "outputId": "f8fddfdf-7c5a-4d7b-da05-5e6f08827516"
      },
      "outputs": [],
      "source": [
        "# Print aggregate results\n",
        "print(\"Aggregate Results:\")\n",
        "print(f\"{'Model':<15} {'Avg PSNR':>10} {'Avg SSIM':>10}\")\n",
        "print(\"-\" * 35)\n",
        "for model, values in avg_metrics.items():\n",
        "    print(f\"{model:<15} {values['PSNR']:10.2f} {values['SSIM']:10.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "mbHM6U9_7HXF"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
